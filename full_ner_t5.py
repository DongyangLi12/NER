# -*- coding: utf-8 -*-
"""Full_NER_T5

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n4uNg0qI3Kct7acMPQZtaEj2-obD0pON
"""

from collections import defaultdict
from sklearn.metrics import f1_score
from urllib import request
import json
import pandas as pd
from math import ceil
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
from tqdm.auto import tqdm

import random
from random import shuffle
import numpy as np
import torch
import torch.nn as nn

SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

def parse_conllu_using_pandas(block):
    records = []
    for line in block.splitlines():
        if not line.startswith('#'):
            records.append(line.strip().split('\t'))
    return pd.DataFrame.from_records(
        records,
        columns=['ID', 'FORM', 'TAG', 'Misc1', 'Misc2'])

def tokens_to_labels(df):
    return (
        df.FORM.tolist(),
        df.TAG.tolist()
    )

PREFIX = "https://raw.githubusercontent.com/UniversalNER/"
DATA_URLS = {
    "en_ewt": {
        "train": "UNER_English-EWT/master/en_ewt-ud-train.iob2",
        "dev": "UNER_English-EWT/master/en_ewt-ud-dev.iob2",
        "test": "UNER_English-EWT/master/en_ewt-ud-test.iob2"
    },
    "en_pud": {
        "test": "UNER_English-PUD/master/en_pud-ud-test.iob2"
    }
}

# en_ewt is the main train-dev-test split
# en_pud is the OOD test set
data_dict = defaultdict(dict)
for corpus, split_dict in DATA_URLS.items():
    for split, url_suffix in split_dict.items():
        url = PREFIX + url_suffix
        with request.urlopen(url) as response:
            txt = response.read().decode('utf-8')
            data_frames = map(parse_conllu_using_pandas,
                              txt.strip().split('\n\n'))
            token_label_alignments = list(map(tokens_to_labels,
                                              data_frames))
            data_dict[corpus][split] = token_label_alignments

# Saving the data so that you don't have to redownload it each time.
with open('ner_data_dict.json', 'w', encoding='utf-8') as out:
    json.dump(data_dict, out, indent=2, ensure_ascii=False)

with open('ner_data_dict.json', 'r', encoding='utf-8') as f:
    data_dict = json.load(f)

train_set = [[[word, label] for word, label in zip(words, labels)] for words, labels in data_dict['en_ewt']['train']]
dev_set = [[[word, label] for word, label in zip(words, labels)] for words, labels in data_dict['en_ewt']['dev']]
test_set = [[[word, label] for word, label in zip(words, labels)] for words, labels in data_dict['en_ewt']['test']]
test_set_ood =  [[[word, label] for word, label in zip(words, labels)] for words, labels in data_dict['en_pud']['test']]

train_set[0]

"""Using T5 to do the original-label NER task"""

labels = set()
for ex in train_set:
    labels.update([el[1] for el in ex])
n_classes = len(labels)
label_list = sorted(labels)

# Check the tokenizaiton of the labels
# for l in label_list:
#     input_ids = tokeniser(l, return_tensors='pt').input_ids.flatten()[:-1].numpy()
#     print(l.ljust(6), '_'.join(repr(tokeniser.decode([iid])) for iid in input_ids))
# the tokenizaiton output of the labels:
# B-LOC  'B'_'-'_'LO'_'C'
# B-ORG  'B'_'-'_'OR'_'G'
# B-PER  'B'_'-'_'PER'
# I-LOC  'I'_'-'_'LO'_'C'
# I-ORG  'I'_'-'_'OR'_'G'
# I-PER  'I'_'-'_'PER'
# O      'O'

def process_batch(batch_inputs, batch_labels,
                  tokeniser, model, device,
                  optimiser):

    optimiser.zero_grad()
    tokenisation = tokeniser(
        batch_inputs,
        return_tensors='pt',
        padding='longest',
        truncation=True
    )
    input_ids = tokenisation.input_ids.to(device)
    attention_mask = tokenisation.attention_mask.to(device)
    labels = tokeniser(
        batch_labels,
        return_tensors='pt',
        padding='longest',
        truncation=True
    ).input_ids.to(device)
    # Stop the model from generating pad tokens
    labels[labels == tokeniser.pad_token_id] = -100
    inputs = {
        'input_ids': input_ids,
        'attention_mask': attention_mask,
        'labels': labels
    }
    loss = model(**inputs).loss
    loss.backward()
    optimiser.step()
    return loss.item()

def prepare_sentence(sentence_array):
    words = []; labels = []
    for word, label in sentence_array:
        words.append(word); labels.append(label)
    prepared_inputs = []
    for i in range(len(words)):
        tmp = words[:i] + ['~', words[i], '~'] + words[i+1:]
        prepared_inputs.append(' '.join(tmp))
    return prepared_inputs, labels

def train_epoch(train_inputs, batch_size,
                tokeniser, model, device, optimizer):
    model.train()

    n_steps = len(train_inputs)
    epoch_losses = torch.zeros(n_steps)
    for outer_step_n in tqdm(range(n_steps), leave=False, desc='Train'):

        prepared_inputs, labels = prepare_sentence(train_inputs[outer_step_n])

        n_batches = ceil(len(prepared_inputs) / batch_size)
        sentence_losses_accum = 0.0
        for batch_n in range(n_batches):
            lo = batch_n * batch_size
            hi = lo + batch_size
            batch_texts = prepared_inputs[lo:hi]
            batch_labels = labels[lo:hi]
            loss = process_batch(batch_texts, batch_labels,
                                 tokeniser, model, device,
                                 optimizer)

            sentence_losses_accum += loss
        epoch_losses[outer_step_n] = sentence_losses_accum / n_batches
    return epoch_losses.mean().item()

def get_class_prediction(prompt, tokeniser, model, device):
    is_batch = isinstance(prompt, (list, tuple))
    batch = prompt if is_batch else [prompt]

    tokenisation = tokeniser(
        batch,
        return_tensors='pt',
        padding   = 'longest',
        truncation=True
    )
    input_ids = tokenisation.input_ids.to(device)
    attention_mask = tokenisation.attention_mask.to(device)
    output = model.generate(
        input_ids=input_ids,
        attention_mask=attention_mask,
        max_new_tokens=5)


    output_string = tokeniser.batch_decode(output,
                                     skip_special_tokens=True
                                     )
    # join the output together
    labels = []
    for txt in output_string:
        lab = "".join(txt.strip().split()) or "O"
        labels.append(lab)

    return labels if is_batch else labels[0]

def get_spans_str(tags):
    labeled = []
    unlabeled = []

    i = 0
    while i < len(tags):
        tag = tags[i]

        # labeled spans
        if tag.startswith('B-'):
            start = i
            cur_lab = tag[2:]
            i += 1
            while i < len(tags) and tags[i].startswith('I-') and tags[i][2:] == cur_lab:
                i += 1
            labeled.append((start, i - 1, cur_lab))
        else:
            i += 1

    # extract unlabeled spans
    i = 0
    while i < len(tags):
        tag = tags[i]

        if tag.startswith('B-'):
            start = i
            i += 1
            while i < len(tags) and tags[i].startswith('I-'):
                i += 1
            unlabeled.append((start, i - 1))
        else:
            i += 1

    return labeled, unlabeled

def validate_epoch(dev_inputs, tokeniser, model, device):
    model.eval()

    correct_unlab = correct_lab = 0

    total_true_lab = 0
    total_true_unlab = 0
    total_pred_lab = 0
    total_pred_unlab = 0

    all_true_labels = []
    all_pred_labels = []


    with torch.no_grad():
      for sentence in tqdm(dev_inputs, desc="Validate"):
        words = [w for w,lab in sentence]
        gold_labels = [lab for w,lab in sentence]

        prepared_inputs, labels = prepare_sentence(sentence)
        pred_labels = get_class_prediction(
                  prepared_inputs, tokeniser, model, device)
        assert len(pred_labels) == len(gold_labels), "Prediction length mismatch!"

        true_lab_spans, true_unlab_spans = get_spans_str(gold_labels)
        pred_lab_spans, pred_unlab_spans = get_spans_str(pred_labels)

        total_true_lab += len(true_lab_spans)
        total_true_unlab += len(true_unlab_spans)
        total_pred_lab += len(pred_lab_spans)
        total_pred_unlab += len(pred_unlab_spans)

        correct_lab   += len(set(true_lab_spans) & set(pred_lab_spans))
        correct_unlab += len(set(true_unlab_spans) & set(pred_unlab_spans))

        all_true_labels.extend(gold_labels)
        all_pred_labels.extend(pred_labels)

    # labeled and unlabeled span score:
    unlabeled_score = correct_unlab / total_true_unlab if total_true_unlab else 0.0
    labeled_score   = correct_lab   / total_true_lab if total_true_lab else 0.0

    # F1 score based on labeled span:
    precision_span = correct_lab / total_pred_lab if total_pred_lab else 0.0
    recall_span    = correct_lab / total_true_lab if total_true_lab else 0.0
    f1_span = (2*precision_span*recall_span/(precision_span+recall_span) if (precision_span+recall_span) else 0.0)


    f1_per_label = f1_score(
        all_true_labels,
        all_pred_labels,
        labels=label_list,
        average=None
    )
    macro_f1 = f1_score(
        all_true_labels,
        all_pred_labels,
        labels=label_list,
        average='macro'
    )
    f1_per_label = dict(zip(label_list, f1_per_label))



    return {

        'unlabeled_span_score': unlabeled_score,
        'labeled_span_score':   labeled_score,
        'f1_span':              f1_span,
        'f1_per_label':         f1_per_label,
        'macro_f1':             macro_f1,
    }

model_tag = 'google-t5/t5-base'

device = 0 if torch.cuda.is_available() else 'cpu'
model = AutoModelForSeq2SeqLM.from_pretrained(
    model_tag, cache_dir='./hf_cache').to(device)
tokeniser = AutoTokenizer.from_pretrained(model_tag)

optim = torch.optim.AdamW(
    model.parameters(),
    # It is recommended to set a higher learning rate for T5
    lr=10**(-4))

n_epochs = 8
batch_size = 16

best = 0.0
patience = 2
epochs_no_improve = 0

for epoch_n in tqdm(range(n_epochs)):
    shuffle(train_set)
    epoch_loss = train_epoch(train_set, batch_size,
                             tokeniser, model, device, optim)
    print(f'Epoch {epoch_n+1} loss:', round(epoch_loss, 2))

    metrics = validate_epoch(
        dev_set, tokeniser, model, device)

    print(f"Unlabeled span match: {metrics['unlabeled_span_score']:.4f}")
    print(f"Labeled span match:   {metrics['labeled_span_score']:.4f}")
    print(f"Span‐level F1:        {metrics['f1_span']:.4f}")
    print("Per‐label F1:")
    for lbl,v in metrics['f1_per_label'].items():
        print(f"  {lbl}: {v:.4f}")
    print(f"Macro‐F1: {metrics['macro_f1']:.4f}")

    f1_now = metrics['f1_span']
    if f1_now > best:
      best = f1_now
      epochs_no_improve = 0
      torch.save(model.state_dict(), 'best_t5.pt')
      print(f"→ New best F1 {best:.4f}, model saved.")
    else:
      epochs_no_improve += 1
      print(f"→ No improvement for {epochs_no_improve} epochs.")
      if epochs_no_improve >= patience:
          print(f"→ Early stopping at epoch {epoch_n}.")
          break

checkpoint = torch.load("best_t5.pt", map_location=torch.device(device))
model.load_state_dict(checkpoint)
model.to(device)
model.eval()
def test_on_split(split, name):
    m = validate_epoch(
        dev_inputs = split,
        tokeniser  = tokeniser,
        model      = model,
        device     = device,
    )
    print(f"\n=== {name} ===")
    print(f"Unlab span match: {m['unlabeled_span_score']:.4f}")
    print(f"Labl span match:  {m['labeled_span_score']:.4f}")
    print(f"Span‐level F1:    {m['f1_span']:.4f}")
    print("Per‐label F1:")
    for lbl,v in m["f1_per_label"].items():
        print(f"  {lbl:>6}: {v:.4f}")
    print(f"Macro‐F1:         {m['macro_f1']:.4f}")

test_on_split(test_set, "In-Domain Test")
test_on_split(test_set_ood,  "Out-of-Domain Test")